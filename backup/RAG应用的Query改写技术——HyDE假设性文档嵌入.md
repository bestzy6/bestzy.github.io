# 简介

> HyDE（Hypothetical Document Embeddings），假设性文档嵌入

HyDE 技术能有效解决搜索效果不佳的问题，尤其是在处理简短或不匹配的查询时更为明显。

HyDE 的独特之处在于**它利用像 GPT 这样的模型生成的假想文档**。这些文档虽然可能包含一些虚构或错误的信息，但能够捕捉到关键的模式。随后，一个智能的文本编码器（如BGE、Bert）将这些假想文档转换成向量形式的嵌入，这有助于在文档库中更准确地找到与查询内容相似的实际文档。

论文实验显示，HyDE 在改善检索效果方面比其他先进技术更为出色，为提升 RAG 系统的性能提供了有效工具。

# 为什么需要HyDE？

有时候，当面对缺乏具体性或缺乏易于从给定上下文中推导答案的元素的问题时，这可能是相当具有挑战性的。

例如，考虑必胜客连锁店的情况，它通常以出售食品而闻名。然而，如果有人询问必胜客的最佳项目，这个问题意味着关注食品。这里的困难在于没有指定的食品项目。因此，寻找见解变得棘手。为了解决这个问题，我们利用LLM（语言模型）的帮助来制定一个假设的答案，然后将其转换为嵌入。然后，在基于语义相似性的向量存储器中检查这些嵌入，以帮助搜索相关信息。

HyDE 使用LLM的帮助创建“假设”答案，然后搜索嵌入以进行匹配。在这里，我们进行的是答案到答案的嵌入相似性搜索，而不是传统的 RAG 检索方法中的查询到答案的嵌入相似性搜索。

![image](https://github.com/user-attachments/assets/11c08398-d5a6-4005-b5e6-32c44983b5b9)

# 使用方式

![image (1)](https://github.com/user-attachments/assets/5d7de319-b5d9-4ff3-982b-a4ef3c8e2700)


如图，先将输入的Query输入HyDE模块（本质上使用LLM），得出NewQuery，再将NewQuery进行嵌入并检索。

# HyDE Prompt

> 需要让LLM给出简短的中文回答。“简短”能够减少文字的生成时间。

```
Given a question, generate a refined paragraph of text that answers the question. Speak in Chinese!

Question: {{query}}

Paragraph:
```

示例：



Given a question, generate a refined paragraph of text that answers the question. Speak in Chinese!

Question: _必胜客哪个披萨好吃_

Paragraph: _必胜客有许多美味的披萨选择，不同的人可能会有不同的偏好。为了提供一个满意的回答，我们需要先了解各种披萨的不同之处。必胜客的招牌披萨有经典芝心披萨、夏威夷披萨、海鲜披萨等，每一款都有着独特的美味和口感。经典芝心披萨，以其丰富的芝士和香甜的果仁作为特色，深受喜爱。夏威夷披萨则以香甜的火腿和新鲜的菠萝相结合，带来酸甜可口的口感。海鲜披萨则注重海鲜的鲜美与披萨面团的融合，满足喜欢海鲜的朋友。所以，选择哪一款披萨好吃，关键在于个人的口味喜好。建议尝试不同口味的披萨，以找到最适合自己味蕾的那一款。_

# 改进措施

可以将原Query与NewQuery进行合并后再Embedding处理，以改善搜索结果。

> LLamaIndex、LangChain框架均已支持这种处理方法。

![image](https://github.com/user-attachments/assets/7ea06b4f-522b-4ad9-98f8-30dcf2db2c81)

# 注意事项

- 假设性文档不适合进行全文检索

  - 文档会引入很多关键词，会扰乱全文检索的结果。

# 缺陷

- 增加了检索时间

  - LLM生成Query的答案、嵌入处理都需要时间。

# 风险

然而，HyDE可能无法始终产生良好的结果。例如，如果讨论的主题对LLM完全陌生，则此方法无效，可能导致生成不正确信息的实例增加。

例如：

```
Q：搜索关于LLM的文档

A：要搜索关于LLM的文档，首先需要明确你是在哪个平台上进行搜索，如在电脑上可以通过搜索引擎（如谷歌搜索、百度搜索）输入关键词“LLM”（法律硕士学位）来获取相关信息。你也可以访问教育机构的官方网站，查找其提供的LLM项目介绍、课程安排、申请要求等详细资料。此外，学术数据库、法律专业论坛、教育论坛等也可能有相关文档或讨论。确保搜索时选择可靠和权威的来源，以获得准确和全面的信息。
```

Qwen2-1.8B会将LLM识别为“法律硕士学位”，而非“大语言模型”。